---
title: "Statistics for Comparisons"
subtitle: "Non-parametric tests"
author: "Andrew Rate"
date: "`r Sys.Date()`"
output: html_document
---

<style type="text/css">
  body{
  font-size: 12pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load addImg fxn and palettes, include=FALSE}
library(png)
addImg <- function(obj, x = NULL, y = NULL, width = NULL, interpolate = TRUE){
  if(is.null(x) | is.null(y) | is.null(width)){stop("Must provide args 'x', 'y', and 'width'")}
  USR <- par()$usr ; PIN <- par()$pin ; DIM <- dim(obj) ; ARp <- DIM[1]/DIM[2]
  WIDi <- width/(USR[2]-USR[1])*PIN[1] ;   HEIi <- WIDi * ARp 
  HEIu <- HEIi/PIN[2]*(USR[4]-USR[3]) 
  rasterImage(image = obj, xleft = x-(width/2), xright = x+(width/2),
            ybottom = y-(HEIu/2), ytop = y+(HEIu/2), interpolate = interpolate)
}
palette(c("black", "#003087", "#DAAA00", "#8F92C4", "#E5CF7E", 
          "#001D51", "#B7A99F", "#A51890", "#C5003E", "#FDC596", 
          "#AD5D1E", "gray40", "gray85", "#FFFFFF", "transparent"))
```

<div style="border: 2px solid #039; padding: 8px;">
<p style="text-align:center; font-size:14pt;">
<em>Comparisons pages</em>: <a href="means.html" style="color:#04b;">Parametric tests</a> | <a
href="nonparam.html" style="color:#04b;">Non-parametric tests</a></p>
</div>

&nbsp;

<div style="border: 2px solid #039; background-color:#e8e8e8; padding: 8px;">

## Activities for this Workshop

> **Before you leave this week&rsquo;s lab, make sure you know <span style="text-decoration: underline;">how</span> and <span style="text-decoration: underline;">when</span> to:**

a. Use a non-parametric *Wilcoxon test* to compare the means of 2 groups of a variable <br />(*i.e*. categorised with a 2-level factor)
  - estimate effect size<br />&nbsp;
b. Use a non-parametric *Kruskal-Wallis test* to compare the means of 3 or more groups of a variable <br />(*i.e*. categorised with a &ge;3-level factor)
  - conduct relevant pairwise comparisons<br />
c. Make *relevant high-quality graphics* to illustrate means comparisons (*e.g*. box plots with means)

### For [parametric means comparisons](means.html) we asked you to learn:

1. Use a *single-sided t- test* to compare the mean of a variable with a fixed value (*e.g*. an environmental guideline)
2. Use a *two -sided Welch's t-test* to compare the means of 2 groups of a variable (*i.e*. categorised with a two-two-level factor)
3. Calculate a *Cohen's d effect size for a 2-group mean comparison*
4. *Make a new factor* using the `cut()` function in R
5. Repeat 1 &amp; 2 above using *analysis of variance* (ANOVA) to compare means for 3 or more groups.
6. Generate a *pairwise comparison of means* from the analysis in step 5.
</div>

<p>&nbsp;</p>

<div style="border: 2px solid #039; background-color:#e8e8e8; padding: 8px;">

## Files and other learning materials

### Supporting Information

<a href="https://lms.uwa.edu.au/bbcswebdav/xid-45752132_1" target="_blank" rel="noopener">ðŸ“°**Decision tree for means comparisons methods**</a><br />(on UWA LMS, login needed)

### Code and Data files

<a href="https://github.com/Ratey-AtUWA/Learn-R-web/raw/main/Learn-R-CODE-meancomps.R" target="_blank" rel="noopener">ðŸ”£ R code file for **Workshop: Advanced Means Comparisons**</a> &ndash; for Week 6, start at**<span style="font-size:9pt; font-family: 'courier new', courier, monospace;"> Non-parametric tests (line 409)**

<a href="https://github.com/Ratey-AtUWA/Learn-R-web/raw/main/sv2017_original.csv">ðŸ“ŠSmith's Lake / Veryard Reserve data (sv2017) in CSV format</a>
</div>

<p>&nbsp;</p>

As usual, we first need to read the data and load the necessary packages:

```{r load workspace and packages invisibly, echo=FALSE, include=FALSE}
sv2017 <- read.csv("../Learn-R-LMS/sv2017_original.csv", stringsAsFactors = TRUE)
sv2017$Reserve <- cut(sv2017$Northing,
                      breaks = c(0,6466530,9999999),
                      labels = c("Smiths","Veryard"))
sv17_soil <- subset(sv2017, subset=sv2017$Type=="Soil")
library(png)
library(car)
library(RcmdrMisc)
library(effsize)
library(rcompanion)
library(multcompView)
knitr::opts_chunk$set(comment="")
```

```{r load workspace and packages visible notrun, eval=FALSE}
sv2017 <- read.csv("sv2017_original.csv", stringsAsFactors = TRUE)
sv2017$Reserve <- cut(sv2017$Northing,
                      breaks = c(0,6466530,9999999),
                      labels = c("Smiths","Veryard"))
sv17_soil <- subset(sv2017, subset=sv2017$Type=="Soil")

library(car)
library(effsize)
library(rcompanion)
library(multcompView)
library(RcmdrMisc)
```

## Non-Parametric Comparisons

We need to use a different type of statistical test if our variable(s) do not 
have a normal distribution (even when log~10~- or power-transformed). The 
*non-parametric* tests are not based on the actual values of our variable, but 
are calculated using the *ranking* (numerical ordering) of each observation.

<center>![](./images/distributions-clique.png){width=500 height=240}</center>

### Note on parametric *vs*. non-parametric tests

There are arguments that the parametric tests (*e.g*. the t-test and analysis of 
variance we covered in [an earlier session on means comparisons](means.html)) 
can be used even if the distributions of variables are not normal. Some authors, 
however, recommend the use of parametric tests in most cases, based on 

i. The tendency for the means subsamples of populations from non-normal
distributions to be nornally distributed, regardless of the shape of the
underlying distribution. This is the *Central Limit Theorem* - see 
[this discussion by James Fogarty of UWA](https://saestatsteaching.tech/nonparametric-methods){target="_blank"}.
Prof Fogarty *et al*. (2021) also mention that parametric tests have greater 
ability to detect differences if their assumptions are met.
ii. The robustness of parametric methods in practice &ndash; see 
[this page by John McDonald from the University of Delaware](https://www.biostathandbook.com/kruskalwallis.html){target="_blank"}.
Prof. McDonald states that &ldquo;...*one-way anova is not very sensitive to deviations from normality*.&rdquo;

We will continue to cover non-parametric comparison tests, but you can make up
your own mind after doing your own research on the pros and cons.

### 1. Wilcoxon test

From previous sessions we know that most untransformed variables are not
normally distributed. For comparison between exactly 2 groups we use the
**Wilcoxon rank-sum test** (via the `wilcox.test()` function). The Wilcoxon 
test is based on ranking of observations, so should be independent of
transformation &ndash; as in the example below:

```{r transform-Na, include=FALSE}
sv17_soil$Na.pow <- sv17_soil$Na^(powerTransform(sv17_soil$Na)$lambda)
```

```{r wilcoxon rank sum test, results='hold'}
wilcox.test(sv17_soil$Na ~ sv17_soil$Reserve)
{cat("Means for original (untransformed) variable\n")
meansNa <- tapply(sv17_soil$Na, sv17_soil$Reserve, mean,
                  na.rm=TRUE)
print(signif(meansNa, 3))
cat("\n--------------------------------------------\n")}
wilcox.test(sv17_soil$Na.pow ~ sv17_soil$Reserve)
{cat("Means for transformed variable\n")
meansNa <- tapply(sv17_soil$Na.pow, sv17_soil$Reserve, mean, na.rm=TRUE)
print(signif(meansNa, 3))}
rm(meansNa) # remove temporary object(s)
```

<p>&nbsp;</p>

The output of `wilcox.test()` above shows a `p-value`&nbsp;<&nbsp;0.05, so we
reject H~0~ (that the rank sum of each group is not different from a case where
the ranks of each group are randomly ordered). In rejecting H~0~ we can accept
the alternative hypothesis, that the distribution of one group is shifted
relative to the other.

It's somewhat important to recognise that the Wilcoxon rank-sum test **does** 
**not compare means** (or even medians). Based on the rank sums of the variable
tested, the Wilcoxon rank-sum test simply tests whether or not the distribution
in one group is shifted relative to the other group. If the distributions in
each group have identical shapes, than we can say that the Wilcoxon test
compares *medians*, but since the distributions are not often identical, our
only conclusions should be about the *'location shift'* of one group's
distribution relative to the other.

The quantity compared in the Wilcoxon test is the *mean rank sum* &ndash; the
sum of the ranks for all observations in a group, divided by the number of
observations in that group.

```{r boxplot-2groups, fig.height=3, fig.width=4, fig.cap="Figure 1: Boxplot showing differences in `Na` between groups defined by `Reserve`, with overplotted individual observations.", message=FALSE, warning=FALSE, results='hold'}
data0 <- na.omit(sv17_soil[,c("Reserve","Na")])
data0 <- data0[order(data0$Na),] ; row.names(data0) <- NULL
par(mar=c(3,3,.5,.5), mgp=c(1.5,0.2,0),tcl=0.2,font.lab=2,las=0)
with(data0, boxplot(Na ~ Reserve))
with(data0, stripchart(Na ~ Reserve, vertical=TRUE, add=TRUE, method="jitter",
                        pch = 19, cex=0.5, col=c("#00308780","#faaa0080")))
```

<p>&nbsp;</p>

```{r Na-as-ranks, fig.height=2, fig.width=10, message=FALSE, warning=FALSE, out.width="75%", fig.cap="Figure 2: Na concentration ranks, the basis for the Wilcoxon rank-sum test, in soil in each reserve area, sampled at Smith's Lake and Charles Veryard Reserves in 2017.", echo=FALSE}
par(mar=c(3,6,1,1), mgp=c(1.3,0.2,0),tcl=0.2,font.lab=2,las=1)
with(data0[which(data0$Reserve=="Smiths"),],
     plot(which(data0$Reserve=="Smiths"),
          rep(1.02, length(which(data0$Reserve=="Smiths"))), 
          xlim=c(2,76), ylim=c(0.95,1.15), cex.lab=1.4, pch="|", 
          col="#008080", cex=3, xlab="Na rank", ylab="", xaxt="n", yaxt="n"))
axis(1, at=seq(0,70,10), labels=seq(0,70,10), tcl=0.3)
axis(1, at=seq(0,80,1), labels=NA)
with(data0[which(data0$Reserve=="Veryard"),],
     points(which(data0$Reserve=="Veryard"),
            rep(1.08, length(which(data0$Reserve=="Veryard"))), ylim=c(0.8,1.4),
            pch="|", col="sienna", cex=3))
axis(2, at=1.02, labels=levels(data0$Reserve)[1], 
     col.axis="cyan4", las=1, cex.axis=1.4)
axis(2, at=1.08, labels=levels(data0$Reserve)[2], 
     col.axis="sienna", las=1, cex.axis=1.4)
```

<p>&nbsp;</p>

#### Effect size

The test we need to use for effect size to accompany rank-based tests like
`wilcox.test()` is not Cohen's d as we use to follow 
[parametric tests](means.html). Non-parametric effect size tests are available
in the `effectsize` R package &ndash; we need the `rank_biserial()` test (also
called `cliffs_delta()`) for a 2-level comparison.

```{r rank_biserial, warning=FALSE, message=FALSE, results='hold'}
require(effectsize)
(rbsNa <- rank_biserial(sv17_soil$Na ~ sv17_soil$Reserve, verbose=F)); cat("\n")
interpret_rank_biserial(rbsNa$r_rank_biserial)
```

<p>&nbsp;</p>

### 2. Kruskal-Wallis test

We use the Kruskal-Wallis test (via the `kruskal.test()` function) for 
non-parametric comparisons between three or more groups defined by a factor.

This example is testing differences in Fe between sample Types in the complete
Smith's &ndash; Veryard 2017 dataset.

```{r Kruskal-Wallis test, results='hold'}
kruskal.test(sv2017$Fe ~ sv2017$Type)
meansFe <- tapply(sv2017$Fe, sv2017$Type, mean,
                  na.rm=TRUE)
cat("Means for untransformed variable\n")
print(signif(meansFe),4)
rm(meansFe)
```

<p>&nbsp;</p>

The output from `kruskal.test()` shows that H~0~ can be rejected, so we can say 
the mean rank sums of each group defined by `Type` are significantly different.

We should note that the Kruskal-Wallis test does **not** compare means, and
would only compare medians if the distributions in each group were the same
shape. The Kruskal-Wallis test is based on the actual and expected values of the
*mean rank sum* in each group, *i.e*., the sum of the ranks in a group divided 
by the number of observations in that group (as for the Wilcoxon test).

```{r boxlot-3groups, fig.height=3, fig.width=4, fig.cap="Figure 3: Boxplot showing differences in `Fe` between groups defined by `Type`, with overplotted individual observations.", message=FALSE, warning=FALSE, results='hold'}
par(mar=c(3,3,.5,.5), mgp=c(1.5,0.2,0),tcl=0.2,font.lab=2,las=0)
with(sv2017, boxplot(Fe ~ Type, log="y", xlab="Sample Type", ylab = "Fe (mg/kg)"))
with(sv2017, stripchart(Fe ~ Type, vertical=TRUE, add=TRUE, method="jitter",
                        pch = 19, cex=0.5, col=c("#00308780","#faaa0080","#60008080")))
```

<p>&nbsp;</p>

With a p-value of &asymp; 0.016, H~0~ can be rejected. We still have the
problem of not knowing which means are significantly different from each other.
There are several options for pairwise comparisons of means following
statistically significant Kruskal-Wallis results; we will use the pairwise
Wilcoxon test (`pairwise.wilcox.test()`), for consistency with the 2-level
comparisons in the previous section. Also, we should still be using a
non-parametric test to match the original Kruskal-Wallis test. (More rigorous
tests, such as Dunn's non-parametric all-pairs comparison test, are available
in the R package `PMCMRplus`).

<p>&nbsp;</p>

```{r Fe-as-ranks, fig.height=2, fig.width=10, message=FALSE, warning=FALSE, out.width="75%", fig.cap="Figure 4: Fe concentration ranks (the basis for the Kruskal-Wallis test) in sediment, soil, and street dust sampled at Smith's Lake and Charles Veryard Reserves in 2017.", echo=FALSE}
data0 <- na.omit(sv2017[,c("Fe","Type")])
data0 <- data0[order(data0$Fe),] ; row.names(data0) <- NULL
par(mar=c(3,6,1,1), mgp=c(1.3,0.2,0),tcl=0.2,font.lab=2,las=1)
with(data0[which(data0$Type=="Sediment"),],
     plot(which(data0$Type=="Sediment"),
          rep(1, length(which(data0$Type=="Sediment"))), 
          xlim=c(2,96), ylim=c(0.95,1.15), cex.lab=1.4,
          pch="|", col="#008080", cex=3, xlab="Fe rank", ylab="", yaxt="n"))
with(data0[which(data0$Type=="Soil"),],
     points(which(data0$Type=="Soil"),
            rep(1.05, length(which(data0$Type=="Soil"))), ylim=c(0.8,1.4),
            pch="|", col="sienna", cex=3))
with(data0[which(data0$Type=="Street dust"),],
     points(which(data0$Type=="Street dust"),
        rep(1.1, length(which(data0$Type=="Street dust"))), ylim=c(0.8,1.4),
            pch="|", col="gray10", cex=3))
axis(2, at=1, labels=levels(data0$Type)[1], 
     col.axis="cyan4", las=1, cex.axis=1.4)
axis(2, at=1.05, labels=levels(data0$Type)[2], 
     col.axis="sienna", las=1, cex.axis=1.4)
axis(2, at=1.1, labels=levels(data0$Type)[3], 
     col.axis="gray10", las=1, cex.axis=1.4)
```

<p>&nbsp;</p>

### Pairwise comparisons following a Kruskal-Wallis test

```{r Kruskal-Wallis-test-wilcox-pairwise-comps, echo=FALSE, warning=FALSE, results='hold'}
with(sv2017, pairwise.wilcox.test(Fe, Type))
```

The pairwise comparisons show that only Soil and Street dust have significantly 
different Fe concentration. *Note* the p-value adjustment &ndash; we still use Holm's 
for multiple non-parametric comparisons.

We can also get a pairwise compact letter display based on the results of
non-parametric tests. As before, we need the **R** packages `rcompanion` and 
`multcompView` to do this easily.

```{r compact-letters-nonparam, message=FALSE, warning=FALSE, results='hold'}
require(rcompanion)
require(multcompView)
pwFe_Type <- with(sv2017, pairwise.wilcox.test(Fe, Type)) 
pwFe_Type_pv <- fullPTable(pwFe_Type$p.value)               # from rcompanion
multcompLetters(pwFe_Type_pv)                               # from multcompView
```

The output from `pairwise.wilcox.test()` shows that p &le; 0.05 only for the
Soil-Street dust comparison (`"ab"` matches `"a"` OR `"b"`). We can't reject 
H~0~ for any other pairwise comparisons. 

<p>&nbsp;</p>

### Effect sizes for the Kruskal-Wallis test

The effect size test to accompany a Kruskal-Wallis test is the 
`rank_epsilon_squared()` test in the `effectsize` R package

```{r rank-epsilon-sq, results='hold'}
(resFe <- rank_epsilon_squared(sv2017$Fe, sv2017$Type, verbose = FALSE))
cat("\n\n") # blank output line
interpret_epsilon_squared(resFe$r)
```

<p>&nbsp;</p>

## References and R Packages

Cohen, J. (1988). *Statistical power analysis for the behavioral sciences (2^nd^ ed.)*. 
New York:Academic Press.

Fogarty, J.J., Rensing, K., & Stuckey, A. (2021). Introduction to R and Statistics: 
UWA School of Agriculture and Environment. [https://saestatsteaching.tech/](https://saestatsteaching.tech/){target="_blank"}

McDonald, J.H. (2014). Kruskalâ€“Wallis test. In *Handbook of Biological Statistics (3^rd^ ed.)*. Sparky House Publishing, Baltimore, Maryland. [https://www.biostathandbook.com/kruskalwallis.html](https://www.biostathandbook.com/kruskalwallis.html){target="_blank"}

Sawilowsky, S.S. (2009). New Effect Size Rules of Thumb. *Journal of Modern Applied Statistical Methods* **8**:597-599.

**Run the R code below to get citation information for the R packages used in** 
**this document**.

```{r R package citations, results='hold'}
citation("car", auto = TRUE)
citation("RcmdrMisc", auto = TRUE)
citation("effectsize", auto = TRUE)
citation("multcomp", auto = TRUE)
citation("PMCMRplus", auto = TRUE)
citation("rcompanion", auto = TRUE)
citation("multcompView", auto = TRUE)
```
