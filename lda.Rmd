---
title: "Multivariate methods - LDA"
subtitle: "Linerar Discriminant Analysis"
author: "Andrew Rate"
date: "`r Sys.Date()`"
output: 
  html_document: 
    code_folding: show
    self_contained: no
    number_sections: no
    smart: no
    toc: no
---

<style type="text/css">
  body{
  font-size: 12pt;
}
</style>

```{r load packages etc., message=FALSE, warning=FALSE, include=FALSE, results='hide'}
library(MASS)
library(car)
library(cluster)
library(factoextra)
library(ggplot2)
library(reshape2)
library(ggpubr)
library(flextable)
library(magrittr)
library(RcmdrMisc)
library(klaR)

set_flextable_defaults(theme_fun = "theme_booktabs", 
                       font.size = 10, font.family = "Arial",
                       padding = 2, text.align = "right")
BorderDk <- officer::fp_border(color = "#B5C3DF", style = "solid", width = 1)
BorderLt <- officer::fp_border(color = "#FFFFFF", style = "solid", width = 1)

UWApal <- c("black", "#003087", "#DAAA00", "#8F92C4", "#E5CF7E", 
          "#001D51", "#B7A99F", "#A51890", "#C5003E", "#FDC596", 
          "#AD5D1E","gray40","gray85","#FFFFFF","transparent"); palette(UWApal)
```

&nbsp;

<div style="border: 2px solid #039; background-color:#e8e8e8; padding: 8px;">
**Data Source**: We are using a curated version of a whole rock major element 
dataset from Hallberg (2006) 
[https://catalogue.data.wa.gov.au/dataset/hallberg-geochemistry](https://catalogue.data.wa.gov.au/dataset/hallberg-geochemistry){target="_blank"}
</div>

&nbsp;

**Linear Discriminant Analysis (LDA)** is a **supervised classification**
method that uses the information from multiple variables to separate the
observations into each of the &lsquo;classes&rsquo; or categories in a factor
variable. LDA is a *supervised* classification since it requires us to use
pre-defined categories in our dataset, rather than identifying the categories
itself. The LDA procedure creates functions of the dataset variables which
maximise the separation between the pre-defined categories. LDA is also
sensitive to compositional closure, as I hope we're starting to expect for
multivariate methods by now! Predicting existing categories is not the most
useful application of LDA &ndash; ideally, we would like to measure some key
variables so we can predict a previously unknown category (a strategy for
machine learning). Towards the end of this section we will divide our dataset
into two groups – one to 'train' our LDA model to generate a set of linear
discriminant functions, which we can then apply to the remaining observations in
our dataset to *validate* our LDA model.

Linear discriminant analysis resembles principal components analysis (PCA), in
that it generates new sets of variables (dimensions) to reduce the complexity
(*i.e*. dimensionality) of multivariate data. Key differences between LDA and
PCA are that:

- the components of PCA capture successively less multivariate *variance* (and 
are are not 'supervised' by pre-defined categories)
- the dimensions of LDA *maximise some measure of separation* between supervised 
categories. 

In LDA, this is achieved by generating new variables (the dimensions) which are 
linear functions of the existing variables in the dataset.

To implement LDA in R, we use the `lda()` function in the `MASS` package 
(Venables and Ripley, 2002). We specify the variables to be considered using a
formula similar to that used for multiple regression, and we set the prior 
(initial) probabilities of an observation being in a particular category at the 
actual frequencies at which those categories occur in the data.

In practice, we apply LDA to a scaled transformations of our variables (*i.e*. 
conversion to Z-scores with mean = 0 and standard deviation = 1). This avoids 
the variables with larger absolute values having an unbalanced effect on the 
results.

&nbsp;

### Load packages, and read and transform data 

```{r setup-show, message=FALSE, warning=FALSE, paged.print=FALSE}
library(MASS)

git <- "https://raw.githubusercontent.com/Ratey-AtUWA/Learn-R-web/main/"
Hallberg <- read.csv(paste0(git,"HallbergTE.csv"), stringsAsFactors = TRUE)
head(Hallberg[,c(15:25,28:37)])

Hallberg_clr <- Hallberg
Hallberg_clr[,c(15:25,28:37)] <- t(apply(Hallberg[,c(15:25,28:37)], MARGIN = 1,
                           FUN = function(x){log(x) - mean(log(x))}))
print(round(head(Hallberg_clr[,c(15:25,28:37)]),2))
```

```{r make-new-Rock-factor-abbrev-names, eval=FALSE, include=FALSE, results='hold'}
# row.names(Hallberg) <- paste0(as.character(Hallberg$Rock),seq(1:NROW(Hallberg)))
# Hallberg$sRock <- as.character(Hallberg$Rock)
# Hallberg$sRock <- gsub("Basaltic Trachyandesite","BT",Hallberg$sRock)
# Hallberg$sRock <- gsub("Basaltic Andesite","BA",Hallberg$sRock)
# Hallberg$sRock <- gsub("Andesite","An",Hallberg$sRock)
# Hallberg$sRock <- gsub("Trachybasalt","TB",Hallberg$sRock)
# Hallberg$sRock <- gsub("Basalt","Ba",Hallberg$sRock)
# Hallberg$sRock <- gsub("Basanite","Bn",Hallberg$sRock)
# Hallberg$sRock <- gsub("Phonotephrite","Pt",Hallberg$sRock)
# Hallberg$sRock <- as.factor(Hallberg$sRock)
```

&nbsp;

## LDA on closed whole rock major element data

We will use LDA to discriminate the rock type, contained in the column
`Rock` in the Hallberg dataset. The variables we will use are the trace
element contents, Co, Cr, Cu, Ni, Rb, Sr, V, Y, Zn, and Zr, and the minor
element Ti (as TiO~2~). We choose these elements as there is reason to believe
that some of these elements can discriminate rocks at the mafic end of the rock
classification spectrum (which includes the rocks in this dataset, all being
&lsquo;greenstones&rsquo;).


```{r LDA closed whole rock data, results='hold', R.options = list(width = 120)}
data0 <- Hallberg
data0[,c(15:25,28:37)] <- scale(data0[,c(15:25,28:37)]) # scale just numeric variables
lda_rock_clos <- lda(formula = Rock ~ Co + Cr + Cu + Ni + Rb + Sr + TiO2 + V + 
                               Y + Zn + Zr, 
                    data = data0,
                    prior = as.numeric(summary(Hallberg$Rock))/nrow(Hallberg)) 
print(lda_rock_clos)
```

&nbsp;

```{r Fig1-correl-matrix-closed, fig.height=6, fig.width=6, out.width="60%", fig.cap="Figure 1: Correlation matrix for closed-set predictors (not part of LDA output)>", message=FALSE, warning=FALSE}
cormat <- rcorr.adjust(data0[,c(16,28:37)], 
                       type="pearson")
cmx <- round(cormat$R$r,3) ; cmx[which(cmx>0.9999)] <- NA
cmx[lower.tri(cmx)] <- NA 
# flextable(as.data.frame(cbind(row.names(cmx),cmx))) |> width(j=1:12, width=1.2, unit="cm") |> 
#   set_header_labels(V1="") |> align(align="right", part="all") |> 
#   set_caption(caption = "")
corrplot::corrplot(cmx, method="ellipse", tl.col=1, addCoef.col=1, 
                   cl.cex=0.95, na.label = " ")
```

&nbsp;

## LDA on open (CLR) whole rock major element data

```{r LDA open whole rock data, message=FALSE, warning=FALSE, results='hold', R.options = list(width = 120)}
data0 <- Hallberg_clr
data0[,c(15:25,28:37)] <- scale(data0[,c(15:25,28:37)]) # scale just numeric variables
lda_rock_open <- lda(formula = Rock ~ Co + Cr + Cu + Ni + Rb + Sr + TiO2 + V + 
                               Y + Zn + Zr, 
                    data = data0,
                    prior = as.numeric(summary(data0$Rock))/nrow(data0)) 
print(lda_rock_open)
```

&nbsp;

```{r Fig2-correl-matrix-CLR, fig.height=6, fig.width=6, out.width="60%", fig.cap="Figure 2: Correlation matrix for clr-transformed predictors (not part of LDA output)>", message=FALSE, warning=FALSE}
cormat <- rcorr.adjust(data0[,c(16,28:37)], 
                       type="pearson")
cmx <- round(cormat$R$r,3) ; cmx[which(cmx>0.9999)] <- NA
cmx[lower.tri(cmx)] <- NA 
# flextable(as.data.frame(cbind(row.names(cmx),cmx))) |> width(j=1:12, width=1.2, unit="cm") |> 
#   set_header_labels(V1="") |> align(align="right", part="all") |> 
#   set_caption(caption = "")
corrplot::corrplot(cmx, method="ellipse", tl.col=1, addCoef.col=1, 
                   cl.cex=0.95, na.label = " ")
```

&nbsp;

The LDA model specified and the prior probabilities are reported back to us in
the output. The *Group means* sub-table in the output contains the centroids of
the categories (5 classes, in our whole rock data) in the n-dimensional space
defined by the n variables used for classification. The *Coefficients of linear*
*discriminants* sub-table essentially defines the linear discriminant functions 
that separate our categories, since each function (LD1, LD2, *etc*.) is a 
linear combination of all the variables. Finally, the *Proportion of trace* 
sub-table gives the *proportions of between-class variance* that are explained 
by successive discriminant functions (*e.g*. for the open Hallberg rock data,
LD1 explains 0.908 (91%) and LD2 explains 0.081 (8.1%) of variance between Rock 
type categories).

[**Note**: sometimes we cannot make an LDA model, because the predictors are
collinear (highly correlated). We may be able to fix this by inspecting a 
correlation matrix for all the predictor variables, and removing *one* variable 
at a time from correlated pairs, then re-running the LDA procedure. By analogy 
with multiple linear regression, this would mean a Pearson's r &ge;&nbsp;0.8.]

&nbsp;

## Visualising LDA separation

### LDA histograms

We can plot the separation achieved by each linear discriminant (LD) function 
by predicting the classification using the input data, then using the 
`ldahist()` function (Venables and Ripley 2002). To see the separation in 
another LDA dimension, we change the subscript in the `predClos$x[,1]` 
option. Histograms (actually drawn with custom code, enabling a plot with a
side-by side comparison) are shown in Figure 3.


```{r Fig3-ldahistComp, fig.align='center', fig.cap="Figure 3: Histograms based on the first linear discriminant function for (a) closed and (b) open (CLR-transformed) whole-rock major element data.", fig.height=14, fig.width=10, out.width="80%", results='hold'}
predClos <- predict(lda_rock_clos, Hallberg[,c(16,28:37)])
predOpen <- predict(lda_rock_open, Hallberg[,c(16,28:37)])
LD1c <- data.frame(Rock=as.character(Hallberg$Rock),LD1=predClos$x[,1])
LD1c$Rock <- factor(LD1c$Rock, levels=levels(Hallberg$Rock))
par(mfcol = c(nlevels(LD1c$Rock),2), mar = c(1,2,1,1), oma = c(1,0,1,0), 
    mgp = c(0.75,0.2,0), tcl=0.15)
for (i in 1:nlevels(LD1c$Rock)){
  with(subset(LD1c, subset=LD1c$Rock==levels(LD1c$Rock)[i]),
       hist(LD1, main = "", breaks = pretty(LD1c$LD1, n=20), col=5,
       xlim = c(min(LD1c$LD1, na.rm=T),max(LD1c$LD1, na.rm=T))))
  box()
  mtext(levels(LD1c$Rock)[i],3,-1.55,adj=0.505, cex = 0.85, font = 2, col=14)
  mtext(levels(LD1c$Rock)[i],3,-1.5, cex = 0.85, font = 2, col = 11)
  if(i==1) mtext("(a) Closed data", 3, 0.5, font=2, cex = 1.4, col = 11)
}

LD1o <- data.frame(Rock=as.character(Hallberg$Rock),LD1=predOpen$x[,1])
LD1o$Rock <- factor(LD1o$Rock, levels=levels(Hallberg$Rock))
for (i in 1:nlevels(LD1o$Rock)){
  with(subset(LD1o, subset=LD1o$Rock==levels(LD1o$Rock)[i]),
       hist(LD1, main = "", breaks = pretty(LD1o$LD1, n=20), col=4,
            xlim = c(min(LD1o$LD1, na.rm=T),max(LD1o$LD1, na.rm=T))))
  box()
  mtext(levels(LD1o$Rock)[i],3,-1.55, adj=0.505, cex = 0.85, font = 2, col=14)
  mtext(levels(LD1o$Rock)[i],3,-1.5, cex = 0.85, font = 2, col = 2)
  if(i==1) mtext("(b) Open data", 3, 0.5, font=2, cex = 1.4, col = 2)
}
```

&nbsp;

The sets of histograms for closed and open data in Figure 3 both
show some separation of categories, but with overlap. Of course this only shows
the separation in one dimension, and two or more dimensions may be needed to
achieve clear separation. We will make plots showing more than one LDA dimension
later.

### Partition plots

Another potentially useful way of showing separation of groups in LDA is to use
a *partition plot*, accessible using the `partimat()` function from the
`klaR` R package (Weihs *et al*. 2005).

```{r Fig4-pplotComp, fig.height=5, fig.width=10, fig.align='center', out.width="100%", fig.cap="Figure 4: Partition plots for (a) closed and (b) open (CLR-transformed) whole rock major element data, based on the TiO₂ and Zr contents. Filled symbols are means in each category, with red letters showing apparently mis-classified observations.", results='hold'}
require(klaR)
par(mfrow = c(1,2),mar = c(3,3,1,1), mgp= c(1.3,0.2,0), tcl=0.2, font.lab=2)
with(Hallberg, 
     drawparti(Rock, TiO2, Zr, method="lda",image.colors = c(10,7,14,13,2:3),
               xlab = expression(bold(paste(TiO[2]," (mg/kg)"))), 
               ylab = expression(bold(paste(Zr," (mg/kg)"))))
     )
mtext("(a)", 3, -1.5, adj=0.05, font=2, cex = 1.2)
with(Hallberg_clr, 
     drawparti(Rock, TiO2, Zr, method="lda",image.colors = c(10,7,14,13,2:3),
               xlab = expression(bold(paste(TiO[2]," (CLR-transformed)"))), 
               ylab = expression(bold(paste(Zr," (CLR-transformed)"))))
     )
mtext("(b)", 3, -1.5, adj=0.95, font=2, cex = 1.2)
```

&nbsp;

Partition plots, such as those  in Figure 4, are presented for single
pairwise combinations of the variables (in this example TiO~2~ and
Zr) used to make the LDA model. We can make different plots by
specifying different variables in the `drawparti()` function. Each such plot
can be considered to be a different view of the data (which of course has 
multiple dimensions). Coloured regions delineate each classification area. Any
observation that falls within a region is predicted to be from a specific
category, with apparent mis-classification in a different color (but we usually 
need more than two dimensions for correct classification). Each plot also
includes the apparent error rate for that view of the data.

&nbsp;

## Scatter Plots resembling biplots

Scatter-plots showing each variable and observation in linear discriminant
dimensions, and grouped by category, are useful for visual assessment of how
well the LDA model separates the observations.

```{r Fig5-LDAclos, fig.height=8, fig.width=8, fig.align='center', out.width="80%", fig.cap="Figure 5: Linear discriminant analysis (LDA) plots for closed rock composition data: (a) variable coefficients in LD1-LD2 space, and predictions for observations in (b) LD1-LD2 space; (c) LD1-LD3 space; (d) LS2-LD4 space. Legend in (a) applies to plots in (b), (c), and (d).", results='hold'}
par(mfrow = c(2,2), mar = c(3.5,3.5,1,1), mgp = c(1.5,0.3,0), tcl = 0.25,
    lend = "square", ljoin = "mitre", cex.main = 0.9, font.lab=2)
palette(c("black", viridis::viridis(6, alp=0.7, end=0.99), "gray","transparent"))
plot(lda_rock_clos$scaling[,1], lda_rock_clos$scaling[,2], type="n",
     xlim = c(-0.5,2.3), # ylim=c(-0.8,1.4), 
     xlab="Linear Discriminant [1]", ylab="Linear Discriminant [2]", 
     main="(a) Variable Coefficients [LD1, LD2]")
abline(v=0,col="grey",lty=2)
abline(h=0,col="grey",lty=2)
text(lda_rock_clos$scaling[,1],lda_rock_clos$scaling[,2],
     labels=names(Hallberg)[c(16,28:37)], pos = c(4,4,2,4,4,1,1,1,4,2,3),
     cex = 1.1, col = 2, offset = 0.2)
mtext("(a)", 3, -1.5, adj = 0.95, cex = 1.2, font = 2)

ldaPred_rock_clos <- predict(lda_rock_clos)

for(i in 1:NROW(lda_rock_clos$scaling)){
  arrows(0,0,lda_rock_clos$scaling[i,1],lda_rock_clos$scaling[i,2],
         length = 0.1, col = 8)
}

plot(ldaPred_rock_clos$x[,1], ldaPred_rock_clos$x[,2],
     bg=c(2:7)[Hallberg_clr$Rock],
     pch=c(21:25,21)[Hallberg_clr$Rock], lwd = 1, cex = 1.5, 
  xlab="Linear Discriminant [1]", ylab="Linear Discriminant [2]", 
  main="Predictions for Observations [LD1, LD2]")
abline(v=0,col="grey",lty=2)
abline(h=0,col="grey",lty=2)
# text(ldaPred_rock_clos$x[,1], ldaPred_rock_clos$x[,2], 
#      labels=as.character(Hallberg$Rock), col=c(2,4,6,3,12)[Hallberg$Rock],
#      pos=1, offset=0.15, cex=0.65)
# legend("bottomright",legend=levels(Hallberg$Rock)[6:13],
#        ncol = 2, col=c(6:13), pch=c(5:12), pt.lwd = 2,
#        title=expression(bold("Rock Type")),
#        bty="n", inset=0.01, 
#        pt.cex=c(1.8,1.8,2,2,1.3), cex=0.9)
mtext("(b)", 3, -1.5, adj = 0.95, cex = 1.2, font = 2)

plot(ldaPred_rock_clos$x[,1], ldaPred_rock_clos$x[,3], 
     bg=c(2:7)[Hallberg_clr$Rock],
     pch=c(21:25,21)[Hallberg_clr$Rock], lwd = 1, cex = 1.5, 
  xlab="Linear Discriminant [1]", ylab="Linear Discriminant [3]", 
  main="Predictions for Observations [LD1, LD3]")
abline(v=0,col="grey",lty=2)
abline(h=0,col="grey",lty=2)
# text(ldaPred_rock_clos$x[,1], ldaPred_rock_clos$x[,3], 
#      labels=Hallberg$Rock, col=c(1:13)[Hallberg$Rock],
#      pos=1, offset=0.15, cex=0.65)
mtext("(c)", 3, -1.5, adj = 0.05, cex = 1.2, font = 2)
legend("topright",legend=levels(Hallberg$Rock), ncol = 1, bty="n", 
       inset=c(0.01,0.04), pt.bg=c(2:7), pch=c(21:25,21), pt.lwd = 1,
    title="Rock Type in (b) - (d)", pt.cex = 1.5, cex = 1.1, y.intersp = 1)

plot(ldaPred_rock_clos$x[,2], ldaPred_rock_clos$x[,4],
     bg=c(2:7)[Hallberg_clr$Rock],
     pch=c(21:25,21)[Hallberg_clr$Rock], lwd = 1, cex = 1.5, 
  xlab="Linear Discriminant [2]", ylab="Linear Discriminant [4]", 
  main="Predictions for Observations [LD2, LD4]")
abline(v=0,col="grey",lty=2)
abline(h=0,col="grey",lty=2)
# text(ldaPred_rock_clos$x[,2], ldaPred_rock_clos$x[,4], 
#      labels=Hallberg$Rock, col=c(2,4,6,3,12)[Hallberg$Rock],
#      pos=1, offset=0.15, cex=0.65)
mtext("(d)", 3, -1.5, adj = 0.05, cex = 1.2, font = 2)
```

&nbsp;

```{r Fig6-LDAopen, fig.height=8, fig.width=8, out.width="70%", fig.align='center', fig.cap="Figure 6: Linear discriminant analysis (LDA) plots for open (CLR-transformed) rock composition data: (a) variable coefficients in LD1-LD2 space, and predictions for observations in (b) LD1-LD2 space; (c) LD1-LD3 space; (d) LS2-LD3 space. Legend in (a) applies to plots (b), (c), and (d).", results='hold'}
par(mfrow = c(2,2), mar = c(3.5,3.5,1,1), mgp = c(1.5,0.3,0), tcl = 0.25,
    lend = "square", ljoin = "mitre", cex.main = 0.9, font.lab=2)
plot(lda_rock_open$scaling[,1], lda_rock_open$scaling[,2], type="n", 
     xlim = c(-0.15,1.3),  ylim = c(-2,1.8), 
     xlab="Linear Discriminant [1]", ylab="Linear Discriminant [2]", 
     main="Variable Coefficients [LD1, LD2]")
abline(v=0,col="grey",lty=2); abline(h=0,col="grey",lty=2)
text(lda_rock_open$scaling[,1], lda_rock_open$scaling[,2], 
     labels=names(Hallberg_clr)[c(16,28:37)],
     pos = c(4,4,1,1,4,4,1,1,4,4,4), cex = 1.1, col = 3, offset=0.2, font=2)
for(i in 1:NROW(lda_rock_open$scaling)){
  arrows(0,0,lda_rock_open$scaling[i,1],lda_rock_open$scaling[i,2],
         length = 0.1, col = 8) }
mtext("(a)", 3, -1.5, adj = 0.05, cex = 1.2, font = 2)

ldaPred_rock_open <- predict(lda_rock_open)

plot(ldaPred_rock_open$x[,1], ldaPred_rock_open$x[,2], 
     bg=c(2:7)[Hallberg$Rock],
     pch=c(21:25,21)[Hallberg$Rock], lwd=1, cex = 1.5, 
     main="Predictions for Observations [LD1, LD2]", 
     xlab="Linear Discriminant [1]", ylab="Linear Discriminant [2]")
abline(v=0,col="grey",lty=2); abline(h=0,col="grey",lty=2)
# text(ldaPred_rock_open$x[,1], ldaPred_rock_open$x[,2], labels=Hallberg$Rock, 
#      col=c(2,4,6,3,12)[Hallberg$Rock], pos=1, offset=0.15, cex=0.65)
mtext("(b)", 3, -1.5, adj = 0.05, cex = 1.2, font = 2)

plot(ldaPred_rock_open$x[,1], ldaPred_rock_open$x[,3], 
     bg=c(2:7)[Hallberg$Rock],
     pch=c(21:25,21)[Hallberg$Rock], lwd=1, cex = 1.5, 
     main="Predictions for Observations [LD1, LD3]", 
     xlab="Linear Discriminant [1]", ylab="Linear Discriminant [3]")
abline(v=0,col="grey",lty=2); abline(h=0,col="grey",lty=2)
# text(ldaPred_rock_open$x[,1], ldaPred_rock_open$x[,3], labels=Hallberg$Rock, 
#      col=c(2,4,6,3,12)[Hallberg$Rock], pos=1, offset=0.15, cex=0.65)
mtext("(c)", 3, -1.5, adj = 0.05, cex = 1.2, font = 2)

plot(ldaPred_rock_open$x[,2], ldaPred_rock_open$x[,4], 
     bg=c(2:7)[Hallberg$Rock],
     pch=c(21:25,21)[Hallberg$Rock], lwd=1, cex = 1.5, 
     main="Predictions for Observations [LD2, LD4]", 
     xlab="Linear Discriminant [2]", ylab="Linear Discriminant [4]")
abline(v=0,col="grey",lty=2); abline(h=0,col="grey",lty=2)
# text(ldaPred_rock_open$x[,2], ldaPred_rock_open$x[,3], labels=Hallberg$Rock, 
#      col=c(2,4,6,3,12)[Hallberg$Rock], pos=1, offset=0.15, cex=0.65)
mtext("(d)", 3, -1.5, adj = 0.95, cex = 1.2, font = 2)
legend("topleft", ncol = 1, legend=levels(Hallberg$Rock), 
       pt.bg=c(2:7), pch=c(21:25,21), pt.lwd = 1,
       bty="n", box.col="grey90", y.intersp = 0.9, 
       title="Rock Type in (b) - (d)",
       box.lwd=2, pt.cex=1.5, cex=1.1)
```

```{r reset par to 1x1, message=FALSE, warning=FALSE, include=FALSE, results='hide'}
par(mfrow=c(1,1))
```

&nbsp;

From the plots in Figure 5 and Figure 6, we can see that the LDA models obtained
are certainly able to separate observations by the selected factor. Firstly,
however, there is a lot of clustering of the predictor variables in Figure 5(a),
which may relate to spurious relationships between variables caused by
compositional closure. This clustering is not so pronounced in Figure 6(a),
since the closure has been removed by CLR-transformation.

Out of the combinations of LDA dimensions selected, the best separation is with
LD2 *vs*. LD1, which is not surprising since these dimensions together account
for about 95% of the between-groups variance &ndash; for both closed and open data.
There is a lot of apparent overlap, but we can not see the true separation in
only 2 dimensions. The LDA performed on open data may result in slightly clearer
separation of samples by Rock category than LDA using closed data, but without a
multidimensional view this is also hard to be sure about.

## Inspecting the agreement between actual and predicted categories in LDA 

To do this easily we just make an R data frame with columns for the actual
categories (from the original data frame) and the predicted categories (from the
prediction objects we just made). We add a column telling us if these two
columns match in each row (which we can see easily, but we use this column to
calculate a numerical prediction accuracy).

We need to make objects containing the LDA predictions:

```{r make objects for LDA preds, results='hold'}
ldaPred_rock_clos <- predict(lda_rock_clos)
ldaPred_rock_open <- predict(lda_rock_open)
```

The code below uses the `head()` function to inspect the first few rows of each
comparison, but we could easily look at the whole comparison data frames using
`print()`.

```{r compare models with reality, paged.print=FALSE, results='hold'}
closComp <- data.frame(Actual = as.character(Hallberg$Rock),
                       Predicted = as.character(ldaPred_rock_clos$class))
closComp$test <- as.character(Hallberg_clr$Rock) == 
  as.character(ldaPred_rock_clos$class)
k = length(which(closComp$test == TRUE))
cat("Predictions by LDA using closed data:",k,"out of",NROW(Hallberg_clr),
    "=",paste0(round(100*k/NROW(Hallberg_clr),1),"% correct\n"))
head(closComp, n = 10)

openComp <- data.frame(Actual = as.character(Hallberg_clr$Rock),
                       Predicted = as.character(ldaPred_rock_open$class))
openComp$test <- as.character(Hallberg_clr$Rock) == 
  as.character(ldaPred_rock_open$class)
k = length(which(openComp$test == TRUE))
cat("\nPredictions by LDA using open data:",k,"out of",NROW(Hallberg_clr),
    "=",paste0(round(100*k/NROW(Hallberg_clr),1),"% correct\n"))
head(openComp, n = 10)
```

For this dataset, it seems as though LDA using either closed open open data is
not that good at predicting the Rock category for each observation! In the
output above, Basalt is mis-identified as Dolerite (which might make sense given
the expected compositional similarity; simplistically, dolerite is a more
coarse-grained version of basalt). It seems to be more common for Basalt to be
mis-identified as Metasediment, which may or not make sense depending on the
composition of the original sediment!

This kind of comparison is not very rigorous, and nor does it address the reason
we might perform a supervised classification like LDA &ndash; to use data to predict
*unknown* categories. The ability of LDA to predict unknown categories can be
addressed by validation procedures, such as the one we investigate below.

&nbsp;

## Assessment of LDA prediction using a training-validation method

One way that we can get a better idea about the usefulness of our classification
models is to perform some validation. This involves 'training' the model on a
subset of our data, and trying to predict the category of a different subset
using the training model. 

This can be done quite simply, by including the `CV = TRUE` option in the
`lda()` function, which implements 'leave one out cross validation'. Simply
stated, this omits one observation at a time, running the LDA on the remaining
data each time, and predicting the probability of the missed observation being
in each category (the *posterior probabilities*). [Each observation is assigned 
to the category with the greatest posterior probability.]

```{r loocv-LDA, message=FALSE, warning=FALSE, paged.print=FALSE, results='hold'}
# leave-one-out cross validation for LDA
data0 <- Hallberg_clr
data0[,c(15:25,28:37)] <- scale(data0[,c(15:25,28:37)]) # scale just numeric variables
lda_rock_open <- lda(formula = Rock ~ Co + Cr + Cu + Ni + Rb + Sr + TiO2 + V + 
                               Y + Zn + Zr, 
                     data = data0,
                     prior = as.numeric(summary(data0$Rock))/nrow(data0), 
                     CV=TRUE) 
preds <- apply(lda_rock_open$posterior, MARGIN = 1,
      FUN = function(x){levels(lda_rock_open$class)[which(x==max(x, na.rm=TRUE))]})
obsvs <- data0$Rock
matches <- data.frame(Pred_class=preds, Actual_class=obsvs, Match=preds==obsvs)
flextable(matches[1:10,]) |> bold(part="header") |> width(width=c(4.8,2.8,3.8), unit="cm") |> 
  set_header_labels(Pred_class="Predicted class", Actual_class="Actual class", 
                    Match="Is LDA correct?") |> 
  set_caption(caption="Table 2: Matches between LDA model and actual data based on clr-transformed major element concentrations in the whole rock dataset compiled by Hallberg (2006). Only the first 10 observations are shown.")
```

&nbsp;

Below we use a related method, using *training* and *validation* subsets of our
data. The idea here is that we divide the dataset into two (the code below
splits the data in half, but other splits could be used, *e.g*. 0.75:0.25). The
first subset of the data is used to generate an LDA model (*i.e*. a set of linear
discriminant functions), which are then used to try and predict the categories
in the other subset. We choose the observations making up each subset randomly.
Of course, this could give us unreliable results if the random selection happens
to be somehow unbalanced, so we repeat the training-validation process many
times to calculate an average prediction rate.

One glitch that can happen is that in selecting a random subset of the data, the
subset may not include any samples from one or more categories. This problem is
more likely if our data have some categories having relatively few observations.
The code below applies an 'error-catching' condition before running the training
LDA, which is that all categories in a random subset need to be populated.

```{r LDA train and predict closed, message=FALSE, warning=FALSE, paged.print=FALSE, results='hold'}
n0 <- 100 # number of iterations
ftrain <- 0.5 # proportion of observations in training set
results <- data.frame(
  Rep = rep(NA, n0),
  matches = rep(NA, n0),
  non_matches = rep(NA, n0),
  success = rep(NA, n0))
train <- sample(1:NROW(Hallberg), round(NROW(Hallberg) * ftrain,0))
# make vector of individual category non-matches
matchByClass <- 
  data.frame(Match1 = rep(0,nlevels(Hallberg$Rock[train]))) 
rownames(matchByClass) <- levels(ldaPred_rock_clos$class)
fMatchXClass <- 
  data.frame(PctMch1 = rep(0,nlevels(Hallberg$Rock[train]))) 
rownames(fMatchXClass) <- levels(ldaPred_rock_clos$class)
# make vector of cumulative category counts in Hallberg[-train] iterations
cc0 <- rep(0,nlevels(Hallberg$Rock))
isOK <- 0 ; i <- 2

for (i in 1:n0) {
  train <- sample(1:NROW(Hallberg), round(NROW(Hallberg) * ftrain,0))
      # set condition requiring all categories to be populated
      if (is.na(match(NA,tapply(Hallberg[train,]$SiO2, 
                      Hallberg[train,]$Rock, sd, na.rm=T))) == TRUE) {
          lda_Rock_train <- lda(formula = Rock ~ Co + Cr + Cu + Ni + Rb + Sr + 
                                  TiO2 + V + Y + Zn + Zr, 
                          data = Hallberg[train,],
                          prior=as.numeric(summary(Hallberg$Rock[train]))/
                            nrow(Hallberg[train,]))
          ldaPred_rock_clos <- predict(lda_Rock_train, Hallberg[-train,])
          isOK <- isOK + 1
        }
  
  k=0               # number of matches
  m0 <-             # vector of individual category matches 
    as.matrix(rep(0,nlevels(Hallberg$Rock[train]))) 
  rownames(m0) <- levels(Hallberg$Rock)
  m1 <-             # vector of fractional category matches 
    as.matrix(rep(0,nlevels(Hallberg$Rock[train]))) 
  rownames(m1) <- levels(Hallberg$Rock)
  for (jM in 1:NROW(Hallberg[-train,])) {
    for (jS in 1:nlevels(ldaPred_rock_clos$class)) {
      if((ldaPred_rock_clos$class[jM] == levels(ldaPred_rock_clos$class)[jS]) & 
         (Hallberg$Rock[-train][jM] == levels(ldaPred_rock_clos$class)[jS]) ) 
        m0[jS] = m0[jS] + 1
      else  m0[jS] = m0[jS] 
    }
    k = sum(m0)
  }
  cc0 <- cc0 + as.numeric(summary(Hallberg$Rock[-train]))
  m1 <- round(100*m0/as.numeric(summary(Hallberg$Rock[-train])),1)
  matchByClass[,paste0("Match",i)] <- m0
  fMatchXClass[,paste0("PctMch",i)] <- m1
  # output to results data frame: iteration, matches, non-matches, proportion matched
  results[i,] <- c(i, k, NROW(Hallberg[-train,])-k, 
                   signif(k/NROW(Hallberg[-train,]),3))
}
# Output code block
cat(paste("[Based on", n0, "random subsets of",paste0(100*ftrain,"%"),
          "of the dataset to train LDA model\n",
     "      to predict remaining observations]\n"))
  cat("Number of obs. in random subsets =",NROW(train),
      " (predicting",NROW(Hallberg)-NROW(train),"samples)\n")
  print(numSummary(results[,2:4], statistics=c("mean","sd"))$table)
  ns0 <- numSummary(results$success)
  t0 <- t.test(results$success)
  cat(rep("-\u2013-",24),
      "\nStat. summary for 'success':\nMean = ",round(ns0$table[1],4),
      ", sd = ",round(ns0$table[2],4),
      ", 95% confidence interval = (",
      signif(t0$conf.int[1],3),", ",signif(t0$conf.int[2],4),
      ") (after ",i," reps)\n", sep="")
  cat(n0-isOK,"iterations 'failed' due to randomisation missing a category\n\n")
  cat("Fraction of matches by category over ALL iterations:\n")
  summCats <- data.frame(
    Rock_Type = row.names(matchByClass),
    Total_Matched = rowSums(matchByClass),
    Actual = cc0,
    Percent_Matched = paste0(round(100*(rowSums(matchByClass)/cc0),1),"%"),
    row.names = NULL)
  print(summCats)
# tidy up
rm(list = c("n0","ftrain","i","isOK","jS","jM","k","m0","m1","t0","cc0",
            "matchByClass","fMatchXClass","results","train","summCats"))
```

The number of iterations makes some difference (Figure 5)!

Based on Figure 7, it looks like we should run at least 50-100 iterations to get
a reasonable idea of how well our LDA model performs. More iterations are
better, but it depends how long you want the run-time to be!

```{r accuracy-vs-iterations, fig.height=3.5, fig.width=5, fig.align='center', message=FALSE, warning=FALSE, out.width="40%", fig.cap="Figure 7: Accuracy (shown by 95 percent CI error bars) as a function of number of train-validate iterations for an LDA model using closed whole-rock composition data.", results='hold'}
par(mar = c(3,3,1,1), mgp = c(1.5,0.2,0), tcl = 0.25, font.lab = 2)
plot(c(10,20,50,100,200,500,1000),c(0.5572,0.5986,0.5848,0.5847,0.5837,0.581,0.582), 
     pch=19, cex = 1.2, log = "x", xlim = c(7,1400), ylim = c(0.45,0.65),
     xlab = "Number of iterations", ylab = "Mean accuracy \u00B1 95% CI")
arrows(c(10,20,50,100,200,500,1000),c(0.49,0.58,0.572,0.574,0.577,0.576,0.579),
       c(10,20,50,100,200,500,1000),c(0.624,0.617,0.598,0.595,0.591,0.586,0.585),
       angle = 90, length = 0.1, code = 3)
```

&nbsp;

We can run a similar validation process for the CLR-transformed data (we don't
show the `code`, as it's effectively identical to the code for validation of LDA
for closed data, but with references to `Hallberg` replaced with
`Hallberg_clr`).

```{r LDA train and predict open, message=FALSE, warning=FALSE, echo=FALSE, paged.print=FALSE, results='hold'}
n0 <- 100 # number of iterations
ftrain <- 0.5 # proportion of observations in training set
results <- data.frame(
  Rep = rep(NA, n0),
  matches = rep(NA, n0),
  non_matches = rep(NA, n0),
  success = rep(NA, n0))
train <- sample(1:NROW(Hallberg_clr), round(NROW(Hallberg_clr) * ftrain,0))
# make vector of individual category non-matches
matchByClass <- 
  data.frame(Match1 = rep(0,nlevels(Hallberg_clr$Rock[train]))) 
rownames(matchByClass) <- levels(ldaPred_rock_open$class)
fMatchXClass <- 
  data.frame(PctMch1 = rep(0,nlevels(Hallberg_clr$Rock[train]))) 
rownames(fMatchXClass) <- levels(ldaPred_rock_open$class)
# make vector of cumulative category counts in Hallberg_clr[-train] iterations
cc0 <- rep(0,nlevels(Hallberg_clr$Rock)) 
isOK <- 0 ; i <- 2

for (i in 1:n0) {
  # train <- sample(1:NROW(Hallberg_clr), round(NROW(Hallberg_clr)-5,0))
  train <- sample(1:NROW(Hallberg_clr), round(NROW(Hallberg_clr) * ftrain,0))
      if (is.na(match(NA,tapply(Hallberg_clr[train,]$TiO2, 
                      Hallberg_clr[train,]$Rock, sd, na.rm=T))) == TRUE) {
          lda_Rock_train <- lda(formula = Rock ~ Co + Cr + Cu + Ni + Rb + Sr + 
                                  TiO2 + V + Y + Zn + Zr, 
                          data = Hallberg_clr[train,],
                          prior=as.numeric(summary(Hallberg_clr$Rock[train]))/
                            nrow(Hallberg_clr[train,]))
          ldaPred_rock_open <- predict(lda_Rock_train, Hallberg_clr[-train,])
          isOK <- isOK + 1
        }
  
  k=0 # number of matches
  m0 <- # vector of individual category matches 
    as.matrix(rep(0,nlevels(Hallberg_clr$Rock[train]))) 
  rownames(m0) <- levels(Hallberg_clr$Rock)
  m1 <- # vector of fractional category matches 
    as.matrix(rep(0,nlevels(Hallberg_clr$Rock[train]))) 
  rownames(m1) <- levels(Hallberg_clr$Rock)
  for (jM in 1:NROW(Hallberg_clr[-train,])) {
    for (jS in 1:nlevels(ldaPred_rock_open$class)) {
      if((ldaPred_rock_open$class[jM] == levels(ldaPred_rock_open$class)[jS]) & 
         (Hallberg_clr$Rock[-train][jM] == levels(ldaPred_rock_open$class)[jS]) ) 
        m0[jS] = m0[jS] + 1
      else  m0[jS] = m0[jS] 
    }
    k = sum(m0)
  }
  cc0 <- cc0 + as.numeric(summary(Hallberg_clr$Rock[-train]))
  m1 <- round(100*m0/as.numeric(summary(Hallberg_clr$Rock[-train])),1)
  matchByClass[,paste0("Match",i)] <- m0
  fMatchXClass[,paste0("PctMch",i)] <- m1
# output to results data frame: iteration, matches, non-matches, proportion matched
  results[i,] <- c(i, k, NROW(Hallberg_clr[-train,])-k, 
                   signif(k/NROW(Hallberg_clr[-train,]),3))
}

cat(paste("[Based on", n0, "random subsets of",paste0(100*ftrain,"%"),
          "of the dataset to train LDA model\n",
     "      to predict remaining observations]\n"))
  cat("Number of obs. in random subsets =",NROW(train),
      " (predicting",NROW(Hallberg_clr)-NROW(train),"samples)\n")
  print(numSummary(results[,2:4], statistics=c("mean","sd"))$table)
  ns0 <- numSummary(results$success)
  t0 <- t.test(results$success)
  cat(rep("-\u2013-",24),
      "\nStat. summary for 'success':\nMean = ",round(ns0$table[1],4),
      ", sd = ",round(ns0$table[2],4),
      ", 95% confidence interval = (",
      signif(t0$conf.int[1],3),", ",signif(t0$conf.int[2],4),
      ") (after ",i," reps)\n", sep="")
  cat(n0-isOK,"iterations 'failed' due to randomisation missing a category\n\n")
  cat("Fraction of matches by category over ALL iterations:\n")
  summCats <- data.frame(
    Rock_Type = row.names(matchByClass),
    Total_Matched = rowSums(matchByClass),
    Actual = cc0,
    Percent_Matched = paste0(round(100*(rowSums(matchByClass)/cc0),1),"%"),
    row.names = NULL)
  print(summCats)
rm(list = c("n0","ftrain","i","isOK","jS","jM","k","m0","m1","t0","cc0",
            "matchByClass","fMatchXClass","results","train","summCats"))
```

&nbsp;

If we compare the validation output for the open data with the results for
closed data, we see very little difference in overall accuracy. Both closed and
open data generated successful predictions 62.7% of the time, with a slightly
lower standard deviation for LDA based on open data. 

There were small differences (in this validation exercise), between closed and
open data, in the ability of LDA to predict specific categories. Closed-data LDA
seemed better at predicting Dolerite, Gabbro, High Mg Basalt, and Metasediment.
Conversely, LDA using open data seemed better at predicting Basalt, Peridotite,
Pyroxenite, and Spinel Peridotite.

We may get better prediction accuracy by including different variables in the
LDA model. The original Hallberg geochemistry data at
https://catalogue.data.wa.gov.au/dataset/hallberg-geochemistry also contain
trace element concentrations, which can sometimes provide better discrimination
than major element concentrations alone. This would be an interesting exercise
to extend one's skills in data curation and multivariate analysis of
compositional data.

&nbsp;

An issue that we haven't considered yet is whether all the variables we used for
prediction are necessary to discriminate the categories in our data (some are
collinear, based on Figure 2). The R package `klaR` (Weihs et al. 2005) includes
the `stepclass()` function, which enables us to refine an LDA model, using a
procedure similar to stepwise selection of predictors in multiple regression.
The next chunk of code implements this approach.

```{r stepwise-lda, message=FALSE, warning=FALSE, results='hold'}
minimp <- c(0.0005,0.001,0.002,0.003,0.005,0.01) ; j <- 1
# for(j in 1:length(minimp)){
  stepwise.lda <- stepclass(formula = Rock ~ Co + Cr + Cu + Ni + Rb + Sr + 
                              TiO2 + V + Y + Zn + Zr, 
                            data = data0, output=TRUE, 
                            prior=as.numeric(summary(data0$Rock))/nrow(data0), 
                            method="lda", improvement=minimp[j], 
                            direction="backward", criterion="AS")
  # }
  cat("Stepwise model: ",deparse(stepwise.lda$formula))
```

&nbsp;

The &lsquo;full&rsquo; LDA model had 11 predictors, but the stepwise model
retains less &ndash; 8-9 predictors, depending on individual code runs and/or
choice of options (see below).

If we run the code above repeatedly, we get different results. We also get
different results if we change the options in `stepclass()` (for example, the
default tolerance specified by `improvement=` is 0.05, which I've found to not
be sensitive enough). We can also specify different criteria to optimise; the
code uses `criterion="AS"`, which is &lsquo;ability to separate&rsquo;, but we
can choose others, such as correctness rate (`CR`, the default), accuracy `AC`,
or confidence `CF`. For full details run `?klaR::stepclass`. If you copy the
code above, uncomment the lines beginning with `#`, and run, you can see what
the effect of changing the improvement tolerance is.

&nbsp;

### References

Hallberg, J.A. (2006). *Greenstone chemistry from the Yilgarn Craton*. Dataset ANZWA1220000718, Department of Energy, Mines, Industry Regulation and Safety, East Perth, Western Australia  [https://catalogue.data.wa.gov.au/dataset/hallberg-geochemistry](https://catalogue.data.wa.gov.au/dataset/hallberg-geochemistry){target="_blank"}.

Reimann, C., Filzmoser, P., Garrett, R. G., and Dutter, R. (2008). *Statistical Data Analysis Explained: Applied Environmental Statistics with R* (First ed.). John Wiley & Sons, Chichester, UK.

Venables, W. N. and Ripley, B. D. (2002) *Modern Applied Statistics with S* (`MASS`). Fourth Edition. Springer, New York. ISBN 0-387-95457-0 [http://www.stats.ox.ac.uk/pub/MASS4/](http://www.stats.ox.ac.uk/pub/MASS4/){target="_blank"}.

Weihs, C., Ligges, U., Luebke, K. and Raabe, N. (2005). `klaR` &ndash; Analyzing 
German Business Cycles. **In** Baier, D., Decker, R. and Schmidt-Thieme, L. 
(eds.). *Data Analysis and Decision Support*, 335-343, Springer-Verlag, Berlin.
